library(huge)
set.seed(42)
huge.out <- huge(Ecoli.expr)
huge.opt <- huge.select(huge.out, criterion="stars")
g.huge <- graph_from_adjacency_matrix((huge.opt$refit, "undirected"))
g.huge <- graph_from_adjacency_matrix(huge.opt$refit, "undirected")
ecount(g.huge)
huge.opt <- huge.select(huge.out, criterion="ric")
g.huge <- graph_from_adjacency_matrix(huge.opt$refit, "undirected")
ecount(g.huge)
huge.opt <- huge.select(huge.out, criterion="stars")
g.huge <- graph_from_adjacency_matrix(huge.opt$refit, "undirected")
summary(g.huge)
ecount(g.huge)
data(sandwichprobe)
delaydata[1:5, ]
host.locs
meanmat <- with(delaydata, by(DelayDiff, list(SmallPktDest, BigPktDest), mean))
image(log(meantime + t(meantime)), xaxt="n", yaxt="n", col=heat.colors(16))
image(log(meanmat + t(meanmat)), xaxt="n", yaxt="n", col=heat.colors(16))
mtex(side=1, text=host.locs, at=seq(0.0, 1.0, 0.11), las=3)
mtext(side=1, text=host.locs, at=seq(0.0, 1.0, 0.11), las=3)
mtex(side=2, text=host.locs, at=seq(0.0, 1.0, 0.11), las=1)
mtext(side=2, text=host.locs, at=seq(0.0, 1.0, 0.11), las=1)
read.csv("C:\Users\arijo\source\repos\iml_project\Task1b\train.csv", header=TRUE)
read.csv("C:\\Users\\arijo\\source\\repos\\iml_project\\Task1b\\train.csv", header=TRUE)
Y
y
rm(list=ls)
rm(list=ls())
rows = read.csv("C:\\Users\\arijo\\source\\repos\\iml_project\\Task1b\\train.csv", header=TRUE)
rows.y
rows$y
data = read.csv("C:\\Users\\arijo\\source\\repos\\iml_project\\Task1b\\train.csv", header=TRUE)
data[2:]
data[2:700]
data[2]
data[2][0]
data[2][1]
data[,1]
data[1,1]
data[3,]
data[0,]
data[1,4:5]
data[1:,]
data[1:-1,]
data[0:-1,]
o = ones
o = ones(1)
o = rep(1, 7)
o = rep(1, 7)
o
o = c(0,0,rep(1, 5))
o
data[xId]
xId = c(0,0,rep(1, 5))
data[xId]
data[,xId]
data[xId,]
data[,xId]
data[3,xId]
data
?c
data[-c(0,1)]
data[3, -c(0,1)]
data[3, -c(0,2)]
data[3, -c(1,2)]
data[3, -c(10,2)]
data[3, -c(0,2)]
data[3, -c(0,1,2)]
data[0]
data[1]
X = data[, -c(1,2)]
X
Y = data[, 1]
Y
Y = data[, 2]
Y
x
for (x in X){
x
}
for (x in X){
x[1]
}
x
}
xId
rm(xId)
ow(X)){
xId
}
for (xId in 1:nrow(X)){
xId
}
for (xId in 1:nrow(X)){
print(xId)
}
for (xId in 1:nrow(X)){
X[xId] = c(X[xId, X[xId]**2])
}
X[xId] = c(X[xId], X[xId]**2)
for (xId in 1:nrow(X)){
X[xId,] = c(X[xId], X[xId]**2)
}
for (xId in 1:nrow(X)){
X[xId,] = c(X[xId,], X[xId,]**2)
}
4**5
x = [1, 2]
o**2
o + 5
o**2
o = o+5
o**2
for (xId in 1:nrow(X)){
X[xId,] = cbind(X[xId,], X[xId,]**2)
}
X = cbind(X, X**2)
X
X = cbind(X, X**2, exp(X), cos(X), rep(1, 700))
X = cbind(X, X**2, exp(X), cos(X))
data = read.csv("C:\\Users\\arijo\\source\\repos\\iml_project\\Task1b\\train.csv", header=TRUE)
X = data[, -c(1,2)]
Y = data[, 2]
X = cbind(X, X**2, exp(X), cos(X))
source('~/R/delete_this.R')
X
?lm
reg = lm(Y ~ X)
reg = lm(X ~ Y)
reg = lm(Y ~ X[,1]+X[,2])
reg = lm(Y ~ X[,1:21])
?sum
reg = lm(Y ~ .,data = X)
X[1]
X[1,]
intall.packages("tidyverse")
install.packages("tidyverse")
data %>%
rename(
sepal_length = Sepal.Length,
sepal_width = Sepal.Width
)
library(tidyverse)
data %>%
rename(
sepal_length = Sepal.Length,
sepal_width = Sepal.Width
)
names(X)[6] <- "x1**2"
X
names(X)[7] <- "x2**2"
names(X)[8] <- "x3**2"
names(X)[9] <- "x4**2"
names(X)[10] <- "x5**2"
names(X)[11] <- "exp(x1)"
names(X)[12] <- "exp(x2)"
names(X)[13] <- "exp(x3)"
names(X)[14] <- "exp(x4)"
names(X)[15] <- "exp(x5)"
names(X)[15] <- "cos(x1)"
names(X)[16] <- "cos(x1)"
names(X)[17] <- "cos(x2)"
names(X)[18] <- "cos(x3)"
names(X)[19] <- "cos(x4)"
names(X)[10] <- "cos(x5)"
names(X)[20] <- "cos(x5)"
names(X)[21] <- "1"
X
names(X)[10] <- "x5**2"
X
names(X)[15] <- "exp(x5)"
X
reg = lm(Y ~ .,data = X)
summary(reg)
authorList <- read.table("C:/Users/arijo/OneDrive/Desktop/8.Semester/Seminar/SCC2016-with-abs/SCC2016/Data/authorList.txt", quote="\"", comment.char="")
View(authorList)
paperList <- read.csv("C:/Users/arijo/OneDrive/Desktop/8.Semester/Seminar/SCC2016-with-abs/SCC2016/Data/paperList.txt")
View(paperList)
install.packages(c("bibtex", "ineq"))
version(igraph)
help version
help(version)
packageVersion("igraph")
source('functions.R') #set the working directory
# required packages
require(igraph)
require(bibtex)
require(ineq)
# read the data
authorPaperBiadj = as.matrix(read.table(file="../Data/authorPaperBiadj.txt",sep="\t", header=F))
# read the data
authorPaperBiadj = as.matrix(read.table(file="SCC2016/Data/authorPaperBiadj.txt",sep="\t", header=F))
# read the data
authorPaperBiadj = as.matrix(read.table(file="./SCC2016/Data/authorPaperBiadj.txt",sep="\t", header=F))
authorList = as.matrix(read.table(file="./SCC2016/Data/authorList.txt",sep="\t", header=F, stringsAsFactors=F))
source('functions.R') #set the working directory
source('Rscript.R') #set the working directory
source('.') #set the working directory
Sys.which("make")
install.packages("jsonlite", type = "source")
writeLines('PATH="$C:\\rtools40\\usr\\bin;${PATH}"', con = "~/.Renviron")
${PATH}
'${PATH}'
install.packages("jsonlite", type = "source")
install.packages("jsonlite", type = "source")
install.packages("stats")
Sys.which("make")
Sys.getenv("PATH")
Sys.getenv("PATH")
Sys.which("make")
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "~/.Renviron")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
rm(list=ls())
source("AriHelpers.R")
# load citations data
load("AuthorCitationWeight.Rda")
W <- (abs(tot.cite+t(tot.cite))+abs(tot.cite-t(tot.cite)))/2 # weighted graph
n <- dim(W) # number of authors
rownames(W) <- colnames(W) <- authors
dim(W)
# Plot all authors
plotNetwork(W)
# build 15-core
converg <- FALSE
old.nrow <- nrow(W)
while(!converg){
d <- colSums(W)
to.keep <- which(d>=15)
if(old.nrow==length(to.keep)){
converg <- TRUE
}
old.nrow <- length(to.keep)
W <- W[to.keep,to.keep]
}
dim(W)
# Plot only authors with (citations > 15)
plotNetwork(W)
# Plot only edges with (weight > 1)
g <- plotNetwork(W, remove=1)
PSVD <- irlba(W,nv=100)
plot(1:100,PSVD$d)
# Stability selection, (Meinshausen & BÃ¼hlmann, 2010)
#result <- foreach(k = 1:100, .packages='irlba')%dopar%{
#set.seed(k)
random.est <- ECV.undirected.Rank.weighted(W,40,B=30,holdout.p=0.1,soft=FALSE,fast=TRUE)
(tmp <- which.min(random.est$sse))
# Select rank
K <- tmp
# Clustering with parameter
tau.seq <- seq(0,3,by=0.1)
set.seed(500)
#system.time(tune <- EdgeCV.REG.DC.Weight(W,h.seq,K=K,B=10,holdout.p=0.1,Arash=TRUE,fast=TRUE))
#saveRDS(tune, file = "tune.Rda")
tune <- readRDS("tune.Rda")
# Pick best tau
best.tau <- tune$gap.min.avg
# Select rank
K <- tmp
# Clustering with parameter
tau.seq <- seq(0,3,by=0.1)
set.seed(500)
#system.time(tune <- EdgeCV.REG.DC.Weight(W,h.seq,K=K,B=10,holdout.p=0.1,Arash=TRUE,fast=TRUE))
#saveRDS(tune, file = "tune.Rda")
tune <- readRDS("tune.Rda")
# Pick best tau
best.tau <- tune$gap.min.avg
# Apply degree regularization
d <- colSums(W)
W.reg <- W + tau.seq[best.tau]*mean(d)/n
d.reg <- colSums(W.reg)
# Laplacian
L <- t(t(W.reg/sqrt(d.reg))/sqrt(d.reg))
# Spectral clustering
# Singular value decomposition
PSVD <- irlba(L,nv=K)
# take K leading eigenvectors, normalize
U <- PSVD$u
norms <- apply(U,1,function(x)sqrt(sum(x^2)))
U.norm <- U/norms
# K-means clustering
set.seed(500)
km <- kmeans(U.norm,centers=K,iter.max=500,nstart=500)
# Separate authors into the K clusters
weighted.label <- km$cluster
weighted.cluster <- list()
for(k in 1:K){
print(tmp.positions <- which(weighted.label==k))
tmp.authors <- authors[weighted.label==k]
tmp.degrees <- d[weighted.label==k]
tmp.index <- sort(tmp.degrees,decreasing=TRUE,index.return=TRUE)$ix
weighted.cluster[[k]] <- cbind(tmp.authors[tmp.index],tmp.degrees[tmp.index],tmp.positions[tmp.index])
}
# Plot the K clusters
plotClusters(g, weighted.cluster, remove=1.0)
# Turn clusters into latex table
df <- rep("",K)
for(k in 1:K){
df[k] <- paste(weighted.cluster[[k]][1:min(20, length(weighted.cluster[[k]][,1])-1),1],collapse=", ")
}
df <- data.frame(authors=df)
library(xtable)
print(xtable(df))
plotClusters(g, weighted.cluster, remove=1.0)
# Turn clusters into latex table
df <- rep("",K)
for(k in 1:K){
df[k] <- paste(weighted.cluster[[k]][1:min(7, length(weighted.cluster[[k]][,1])-1),1],collapse=", ")
}
df <- data.frame(authors=df)
library(xtable)
print(xtable(df))
authors <- rownames(W)
df <- rep("",K)
for(k in 1:K){
df[k] <- paste(weighted.cluster[[k]][1:min(7, length(weighted.cluster[[k]][,1])-1),1],collapse=", ")
}
df <- data.frame(authors=df)
library(xtable)
print(xtable(df))
weighted.label <- km$cluster
weighted.cluster <- list()
for(k in 1:K){
print(tmp.positions <- which(weighted.label==k))
tmp.authors <- authors[weighted.label==k]
tmp.degrees <- d[weighted.label==k]
tmp.index <- sort(tmp.degrees,decreasing=TRUE,index.return=TRUE)$ix
weighted.cluster[[k]] <- cbind(tmp.authors[tmp.index],tmp.degrees[tmp.index],tmp.positions[tmp.index])
}
# Plot the K clusters
plotClusters(g, weighted.cluster, remove=1.0)
# Turn clusters into latex table
df <- rep("",K)
for(k in 1:K){
df[k] <- paste(weighted.cluster[[k]][1:min(7, length(weighted.cluster[[k]][,1])-1),1],collapse=", ")
}
df <- data.frame(authors=df)
library(xtable)
print(xtable(df))
# Pick best tau
best.tau <- tune$gap.min.stable
# Apply degree regularization
d <- colSums(W)
W.reg <- W + tau.seq[best.tau]*mean(d)/n
d.reg <- colSums(W.reg)
# Laplacian
L <- t(t(W.reg/sqrt(d.reg))/sqrt(d.reg))
# Spectral clustering
# Singular value decomposition
PSVD <- irlba(L,nv=K)
# take K leading eigenvectors, normalize
U <- PSVD$u
norms <- apply(U,1,function(x)sqrt(sum(x^2)))
U.norm <- U/norms
# K-means clustering
set.seed(500)
km <- kmeans(U.norm,centers=K,iter.max=500,nstart=500)
# Separate authors into the K clusters
weighted.label <- km$cluster
weighted.cluster <- list()
for(k in 1:K){
print(tmp.positions <- which(weighted.label==k))
tmp.authors <- authors[weighted.label==k]
tmp.degrees <- d[weighted.label==k]
tmp.index <- sort(tmp.degrees,decreasing=TRUE,index.return=TRUE)$ix
weighted.cluster[[k]] <- cbind(tmp.authors[tmp.index],tmp.degrees[tmp.index],tmp.positions[tmp.index])
}
# Plot the K clusters
plotClusters(g, weighted.cluster, remove=1.0)
random.est <- ECV.undirected.Rank.weighted(W,40,B=30,holdout.p=0.1,soft=FALSE,fast=TRUE)
(tmp <- which.min(random.est$sse))
#}
# Count rank occurences
#SSE.K <- unlist(result)
#(occurences <- table(SSE.K))
#plot(occurences)
# Select rank
K <- tmp
# (K <- as.numeric(names(which.max(occurences))))
# Clustering with parameter
tau.seq <- seq(0,3,by=0.1)
set.seed(500)
#system.time(tune <- EdgeCV.REG.DC.Weight(W,h.seq,K=K,B=10,holdout.p=0.1,Arash=TRUE,fast=TRUE))
#saveRDS(tune, file = "tune.Rda")
tune <- readRDS("tune.Rda")
# Pick best tau
best.tau <- tune$gap.min.stable
# Apply degree regularization
d <- colSums(W)
W.reg <- W + tau.seq[best.tau]*mean(d)/n
d.reg <- colSums(W.reg)
# Laplacian
L <- t(t(W.reg/sqrt(d.reg))/sqrt(d.reg))
# Spectral clustering
# Singular value decomposition
PSVD <- irlba(L,nv=K)
# take K leading eigenvectors, normalize
U <- PSVD$u
norms <- apply(U,1,function(x)sqrt(sum(x^2)))
U.norm <- U/norms
# K-means clustering
set.seed(500)
km <- kmeans(U.norm,centers=K,iter.max=500,nstart=500)
# Separate authors into the K clusters
weighted.label <- km$cluster
weighted.cluster <- list()
for(k in 1:K){
print(tmp.positions <- which(weighted.label==k))
tmp.authors <- authors[weighted.label==k]
tmp.degrees <- d[weighted.label==k]
tmp.index <- sort(tmp.degrees,decreasing=TRUE,index.return=TRUE)$ix
weighted.cluster[[k]] <- cbind(tmp.authors[tmp.index],tmp.degrees[tmp.index],tmp.positions[tmp.index])
}
# Plot the K clusters
plotClusters(g, weighted.cluster, remove=1.0)
# Turn clusters into latex table
df <- rep("",K)
for(k in 1:K){
df[k] <- paste(weighted.cluster[[k]][1:min(7, length(weighted.cluster[[k]][,1])-1),1],collapse=", ")
}
df <- data.frame(authors=df)
library(xtable)
print(xtable(df))
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
rm(list=ls())
source("AriHelpers.R")
# load citations data
load("AuthorCitationWeight.Rda")
W <- (abs(tot.cite+t(tot.cite))+abs(tot.cite-t(tot.cite)))/2 # weighted graph
n <- dim(W) # number of authors
rownames(W) <- colnames(W) <- authors
dim(W)
# Plot all authors
plotNetwork(W)
# build 15-core
converg <- FALSE
old.nrow <- nrow(W)
while(!converg){
d <- colSums(W)
to.keep <- which(d>=15)
if(old.nrow==length(to.keep)){
converg <- TRUE
}
old.nrow <- length(to.keep)
W <- W[to.keep,to.keep]
}
authors <- rownames(W)
dim(W)
# Plot only authors with (citations > 15)
plotNetwork(W)
# Plot only edges with (weight > 1)
g <- plotNetwork(W, remove=1)
PSVD <- irlba(W,nv=100)
plot(1:100,PSVD$d)
# Stability selection, (Meinshausen & BÃ¼hlmann, 2010)
#result <- foreach(k = 1:100, .packages='irlba')%dopar%{
#set.seed(k)
random.est <- ECV.undirected.Rank.weighted(W,40,B=30,holdout.p=0.1,soft=FALSE,fast=TRUE)
(tmp <- which.min(random.est$sse))
#}
# Count rank occurences
#SSE.K <- unlist(result)
#(occurences <- table(SSE.K))
#plot(occurences)
# Select rank
K <- tmp
# (K <- as.numeric(names(which.max(occurences))))
# Clustering with parameter
tau.seq <- seq(0,3,by=0.1)
set.seed(500)
#system.time(tune <- EdgeCV.REG.DC.Weight(W,h.seq,K=K,B=10,holdout.p=0.1,Arash=TRUE,fast=TRUE))
#saveRDS(tune, file = "tune.Rda")
tune <- readRDS("tune.Rda")
# Pick best tau
best.tau <- tune$gap.min.stable
# Apply degree regularization
d <- colSums(W)
W.reg <- W + tau.seq[best.tau]*mean(d)/n
d.reg <- colSums(W.reg)
# Laplacian
L <- t(t(W.reg/sqrt(d.reg))/sqrt(d.reg))
# Spectral clustering
# Singular value decomposition
PSVD <- irlba(L,nv=K)
# take K leading eigenvectors, normalize
U <- PSVD$u
norms <- apply(U,1,function(x)sqrt(sum(x^2)))
U.norm <- U/norms
# K-means clustering
set.seed(500)
km <- kmeans(U.norm,centers=K,iter.max=500,nstart=500)
# Separate authors into the K clusters
weighted.label <- km$cluster
weighted.cluster <- list()
for(k in 1:K){
print(tmp.positions <- which(weighted.label==k))
tmp.authors <- authors[weighted.label==k]
tmp.degrees <- d[weighted.label==k]
tmp.index <- sort(tmp.degrees,decreasing=TRUE,index.return=TRUE)$ix
weighted.cluster[[k]] <- cbind(tmp.authors[tmp.index],tmp.degrees[tmp.index],tmp.positions[tmp.index])
}
# Plot the K clusters
plotClusters(g, weighted.cluster, remove=1.0)
# Turn clusters into latex table
df <- rep("",K)
for(k in 1:K){
df[k] <- paste(weighted.cluster[[k]][1:min(7, length(weighted.cluster[[k]][,1])-1),1],collapse=", ")
}
df <- data.frame(authors=df)
library(xtable)
print(xtable(df))
